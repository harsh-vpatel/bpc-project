{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNIzGiWUJv2hfzx4rJDxMMa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilsimda/bpc-project/blob/main/Train_HSB_DE_BPE_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Set up Repo"
      ],
      "metadata": {
        "id": "VVrkyJAbhKN3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUQpx8I9dPev",
        "outputId": "28fe8ade-cc7a-4f23-82cc-0b6aefb52915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'bpc-project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nilsimda/bpc-project.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd bpc-project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDy3KGFGdVFt",
        "outputId": "9ce2ca3f-add5-4328-c1e0-7e9c009dd39f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bpc-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv sync"
      ],
      "metadata": {
        "id": "9ghAkuNefPnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare Dataset"
      ],
      "metadata": {
        "id": "jf-BhdilhS5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!uv run ./prepare.sh bpe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4NJqFmcg70M",
        "outputId": "d52a1d52-0644-465a-a69f-294018052d42"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using segmentation method: bpe\n",
            "Starting preprocessing for hsb-de with bpe...\n",
            "Step 1-5: Processing train/dev/test splits through Moses pipeline...\n",
            "Processing train split...\n",
            "Tokenizer Version 1.1\n",
            "Language: hsb\n",
            "Number of threads: 1\n",
            "WARNING: No known abbreviations for language 'hsb', attempting fall-back to English version...\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 1\n",
            "clean-corpus.perl: processing ./dataset/output_moses/train.tok.hsb & .de to ./dataset/output_moses/train.clean, cutoff 1-100, ratio 9\n",
            "..........(100000)..........(200000)..........(300000)..........(400000)....\n",
            "Input sentences: 449058  Output sentences:  449057\n",
            "Processing dev split...\n",
            "Tokenizer Version 1.1\n",
            "Language: hsb\n",
            "Number of threads: 1\n",
            "WARNING: No known abbreviations for language 'hsb', attempting fall-back to English version...\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 1\n",
            "Processing test split...\n",
            "Tokenizer Version 1.1\n",
            "Language: hsb\n",
            "Number of threads: 1\n",
            "WARNING: No known abbreviations for language 'hsb', attempting fall-back to English version...\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 1\n",
            "Step 4: Training truecaser on training data...\n",
            "Step 5: Applying truecasing to all splits...\n",
            "Step 6: Learning BPE on training data...\n",
            "Combined training data has 898114 lines\n",
            "100% 16000/16000 [01:01<00:00, 260.89it/s]\n",
            "BPE codes learned successfully (16001 operations)\n",
            "Step 7: Applying bpe to all splits...\n",
            "Step 8: Creating fairseq binary dataset...\n",
            "2025-06-23 11:26:08 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='hsb', target_lang='de', trainpref='./dataset/output_bpe/train.bpe', validpref='./dataset/output_bpe/dev.bpe', testpref='./dataset/output_bpe/test.bpe', align_suffix=None, destdir='./dataset/fairseq_bpe', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=4, dict_only=False)\n",
            "2025-06-23 11:26:53 | INFO | fairseq_cli.preprocess | [hsb] Dictionary: 11024 types\n",
            "2025-06-23 11:28:09 | INFO | fairseq_cli.preprocess | [hsb] ./dataset/output_bpe/train.bpe.hsb: 449057 sents, 8965710 tokens, 0.0% replaced (by <unk>)\n",
            "2025-06-23 11:28:09 | INFO | fairseq_cli.preprocess | [hsb] Dictionary: 11024 types\n",
            "2025-06-23 11:28:10 | INFO | fairseq_cli.preprocess | [hsb] ./dataset/output_bpe/dev.bpe.hsb: 4001 sents, 74783 tokens, 0.00401% replaced (by <unk>)\n",
            "2025-06-23 11:28:10 | INFO | fairseq_cli.preprocess | [hsb] Dictionary: 11024 types\n",
            "2025-06-23 11:28:10 | INFO | fairseq_cli.preprocess | [hsb] ./dataset/output_bpe/test.bpe.hsb: 2000 sents, 37515 tokens, 0.00267% replaced (by <unk>)\n",
            "2025-06-23 11:28:10 | INFO | fairseq_cli.preprocess | [de] Dictionary: 10240 types\n",
            "2025-06-23 11:29:16 | INFO | fairseq_cli.preprocess | [de] ./dataset/output_bpe/train.bpe.de: 449057 sents, 9476472 tokens, 0.0% replaced (by <unk>)\n",
            "2025-06-23 11:29:16 | INFO | fairseq_cli.preprocess | [de] Dictionary: 10240 types\n",
            "2025-06-23 11:29:16 | INFO | fairseq_cli.preprocess | [de] ./dataset/output_bpe/dev.bpe.de: 4001 sents, 78700 tokens, 0.00127% replaced (by <unk>)\n",
            "2025-06-23 11:29:16 | INFO | fairseq_cli.preprocess | [de] Dictionary: 10240 types\n",
            "2025-06-23 11:29:17 | INFO | fairseq_cli.preprocess | [de] ./dataset/output_bpe/test.bpe.de: 2000 sents, 39531 tokens, 0.0% replaced (by <unk>)\n",
            "2025-06-23 11:29:17 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./dataset/fairseq_bpe\n",
            "Fairseq binary dataset created successfully!\n",
            "=== Preprocessing Statistics ===\n",
            "=== Original Split Statistics ===\n",
            "Training sentences: 449058\n",
            "Development sentences: 4001\n",
            "Test sentences: 2000\n",
            "\n",
            "=== After Moses Processing ===\n",
            "Training sentences: 449057\n",
            "Development sentences: 4001\n",
            "Test sentences: 2000\n",
            "BPE operations: 16000\n",
            "\n",
            "Preprocessing complete!\n",
            "\n",
            "=== Directory Structure ===\n",
            "./dataset/original/ - Original train/dev/test split files\n",
            "./dataset/output_moses/ - Moses preprocessing output, train/dev/test splits\n",
            "./dataset/output_bpe/ - BPE codes/models and tokenized files\n",
            "./dataset/fairseq_bpe/ - Fairseq binary dataset (ready for training)\n",
            "\n",
            "=== Key Files for NMT Training ===\n",
            "Fairseq binary data: ./dataset/fairseq_bpe/\n",
            "BPE codes: ./dataset/output_bpe/bpe.codes\n",
            "Truecaser models: ./dataset/output_moses/truecase-model.hsb, ./dataset/output_moses/truecase-model.de\n",
            "\n",
            "Ready for NMT training with bpe segmentation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train the model with Fairseq"
      ],
      "metadata": {
        "id": "H0t9W4m3iyCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to log to the Wandb project you can add --wandb-project YOUR_WANDB_PROJECT. Additionally for a real run the number of epochs should be increased."
      ],
      "metadata": {
        "id": "XYHU_W4llY6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_VISIBLE_DEVICES=0 && uv run fairseq-train \\\n",
        "  ./dataset/fairseq_bpe \\\n",
        "  --arch transformer_iwslt_de_en \\\n",
        "  --max-epoch 1 \\\n",
        "  --patience 10 \\\n",
        "  --save-interval 1 \\\n",
        "  --validate-interval 1 \\\n",
        "  --share-decoder-input-output-embed \\\n",
        "  --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
        "  --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
        "  --dropout 0.3 --weight-decay 0.0001 \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --max-tokens 4096 \\\n",
        "  --eval-bleu \\\n",
        "  --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n",
        "  --eval-bleu-detok moses \\\n",
        "  --eval-bleu-remove-bpe \\\n",
        "  --eval-bleu-print-samples \\\n",
        "  --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n",
        "  --save-dir checkpoints/sorbian_german_bpe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPyoF3cghW_K",
        "outputId": "e4643ef6-1432-46cd-9969-7d401a8d6228"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-23 11:32:09 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints/sorbian_german_bpe', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_iwslt_de_en', max_epoch=1, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints/sorbian_german_bpe', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='./dataset/fairseq_bpe', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_attention_heads=4, encoder_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_iwslt_de_en'), 'task': {'_name': 'translation', 'data': './dataset/fairseq_bpe', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2025-06-23 11:32:09 | INFO | fairseq.tasks.translation | [hsb] dictionary: 11024 types\n",
            "2025-06-23 11:32:09 | INFO | fairseq.tasks.translation | [de] dictionary: 10240 types\n",
            "2025-06-23 11:32:10 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(11024, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(10240, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=512, out_features=10240, bias=False)\n",
            "  )\n",
            ")\n",
            "2025-06-23 11:32:10 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2025-06-23 11:32:10 | INFO | fairseq_cli.train | model: TransformerModel\n",
            "2025-06-23 11:32:10 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2025-06-23 11:32:10 | INFO | fairseq_cli.train | num. shared model params: 42,430,464 (num. trained: 42,430,464)\n",
            "2025-06-23 11:32:10 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2025-06-23 11:32:10 | INFO | fairseq.data.data_utils | loaded 4,001 examples from: ./dataset/fairseq_bpe/valid.hsb-de.hsb\n",
            "2025-06-23 11:32:10 | INFO | fairseq.data.data_utils | loaded 4,001 examples from: ./dataset/fairseq_bpe/valid.hsb-de.de\n",
            "2025-06-23 11:32:10 | INFO | fairseq.tasks.translation | ./dataset/fairseq_bpe valid hsb-de 4001 examples\n",
            "2025-06-23 11:32:11 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2025-06-23 11:32:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2025-06-23 11:32:11 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.741 GB ; name = Tesla T4                                \n",
            "2025-06-23 11:32:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2025-06-23 11:32:11 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2025-06-23 11:32:11 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
            "2025-06-23 11:32:11 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/sorbian_german_bpe/checkpoint_last.pt\n",
            "2025-06-23 11:32:11 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/sorbian_german_bpe/checkpoint_last.pt\n",
            "2025-06-23 11:32:11 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2025-06-23 11:32:11 | INFO | fairseq.data.data_utils | loaded 449,057 examples from: ./dataset/fairseq_bpe/train.hsb-de.hsb\n",
            "2025-06-23 11:32:11 | INFO | fairseq.data.data_utils | loaded 449,057 examples from: ./dataset/fairseq_bpe/train.hsb-de.de\n",
            "2025-06-23 11:32:11 | INFO | fairseq.tasks.translation | ./dataset/fairseq_bpe train hsb-de 449057 examples\n",
            "2025-06-23 11:32:11 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp\n",
            "2025-06-23 11:32:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2444\n",
            "epoch 001:   0% 0/2444 [00:00<?, ?it/s]2025-06-23 11:32:11 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2025-06-23 11:32:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/content/bpc-project/.venv/lib/python3.10/site-packages/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  warnings.warn(\n",
            "epoch 001:   0% 1/2444 [00:01<41:53,  1.03s/it]/content/bpc-project/.venv/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "epoch 001: 100% 2443/2444 [13:15<00:00,  3.22it/s, loss=7.5, nll_loss=6.538, ppl=92.92, wps=11615.6, ups=3.06, wpb=3797, bsz=174.6, num_updates=2400, lr=0.0003, gnorm=1.508, train_wall=32, gb_free=12.4, wall=783]2025-06-23 11:45:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A2025-06-23 11:45:29 | INFO | fairseq.tasks.translation | example hypothesis: hast hast du schon schon ihre Geld geschrieben?\n",
            "2025-06-23 11:45:29 | INFO | fairseq.tasks.translation | example reference: hast du schon deinen Urlaub geplant?\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   4% 1/28 [00:01<00:33,  1.23s/it]\u001b[A2025-06-23 11:45:30 | INFO | fairseq.tasks.translation | example hypothesis: ich dachte sich und ununununununununun!\n",
            "2025-06-23 11:45:30 | INFO | fairseq.tasks.translation | example reference: fürchte dich nicht und verzage nicht!\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   7% 2/28 [00:02<00:30,  1.18s/it]\u001b[A2025-06-23 11:45:31 | INFO | fairseq.tasks.translation | example hypothesis: die Wasser- ist in Dresden in einigen einigen Ländern auf einigen Aooooen möglich.\n",
            "2025-06-23 11:45:31 | INFO | fairseq.tasks.translation | example reference: Wassersport ist in Dresden auf einigen Seen möglich.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  11% 3/28 [00:03<00:27,  1.09s/it]\u001b[A2025-06-23 11:45:32 | INFO | fairseq.tasks.translation | example hypothesis: einige sagen sagen, dass sie durch die drei Stöchen gezogen haben.\n",
            "2025-06-23 11:45:32 | INFO | fairseq.tasks.translation | example reference: einige sagen, dass sie über dreißig Morgen gekauft haben.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  14% 4/28 [00:04<00:25,  1.05s/it]\u001b[A2025-06-23 11:45:33 | INFO | fairseq.tasks.translation | example hypothesis: die Lausitz ist so so so so möglich, dass ich die Woche 30 30 30 30 30 30 30 30 30.\n",
            "2025-06-23 11:45:33 | INFO | fairseq.tasks.translation | example reference: die Praxis ist so, dass ich wöchentlich 30 Stunden arbeite.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  18% 5/28 [00:05<00:24,  1.06s/it]\u001b[A2025-06-23 11:45:34 | INFO | fairseq.tasks.translation | example hypothesis: das Programm wurde das Jahr am vergangenen Februar von drei Arbeitsgabe zu unterstützen.\n",
            "2025-06-23 11:45:34 | INFO | fairseq.tasks.translation | example reference: das Dokument wurde am 15. Februar 2016 von allen drei Förderern unterschrieben.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  21% 6/28 [00:06<00:23,  1.05s/it]\u001b[A2025-06-23 11:45:35 | INFO | fairseq.tasks.translation | example hypothesis: gerade hier ist hier auch die Frau immer, das haben?\n",
            "2025-06-23 11:45:35 | INFO | fairseq.tasks.translation | example reference: genau hier hat Susanne auch immer gesessen, haben sie das gewusst?\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  25% 7/28 [00:07<00:21,  1.02s/it]\u001b[A2025-06-23 11:45:36 | INFO | fairseq.tasks.translation | example hypothesis: der Tod, sich die Leute der Leute, ist die Verweiung von der Veränung.\n",
            "2025-06-23 11:45:36 | INFO | fairseq.tasks.translation | example reference: der Tod, den die Menschen fürchten, ist die Trennung der Seele vom Körper.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  29% 8/28 [00:08<00:19,  1.04it/s]\u001b[A2025-06-23 11:45:37 | INFO | fairseq.tasks.translation | example hypothesis: beide war der Schleifer Schleifer Verein gegründet und sie nahm ihr ihr an den Vorgang auf den Aufstand.\n",
            "2025-06-23 11:45:37 | INFO | fairseq.tasks.translation | example reference: beides hatte der Schleifer Verein herausgegeben und bot sie den Besuchern zum Verkauf an.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  32% 9/28 [00:09<00:18,  1.01it/s]\u001b[A2025-06-23 11:45:38 | INFO | fairseq.tasks.translation | example hypothesis: ihr verschcken bei der Lasten der ganze Nacht über die ganze Nacht über die Nacht.\n",
            "2025-06-23 11:45:38 | INFO | fairseq.tasks.translation | example reference: ihr unterhaltet euch am Lagerfeuer die ganze Nacht über Liebe.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  36% 10/28 [00:10<00:18,  1.04s/it]\u001b[A2025-06-23 11:45:39 | INFO | fairseq.tasks.translation | example hypothesis: in diesem Jahr wird dazu Jahre Jahre Jahre Jahre Jahre Jahre, dass das Museum in der bisherigen Öffentlichkeit überteilt wird.\n",
            "2025-06-23 11:45:39 | INFO | fairseq.tasks.translation | example reference: dieses Jahr sind es zwanzig Jahre, dass das Museum in seiner jetzigen Form der Öffentlichkeit übergeben wurde.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  39% 11/28 [00:11<00:18,  1.07s/it]\u001b[A2025-06-23 11:45:40 | INFO | fairseq.tasks.translation | example hypothesis: habt ihr die Augen, dass Sie uns zuerst unsere Schlechen hingetreten wollen?\n",
            "2025-06-23 11:45:40 | INFO | fairseq.tasks.translation | example reference: sind Sie sicher, dass Sie sich nicht zuerst unsere billigeren Modelle anschauen wollen?\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  43% 12/28 [00:12<00:16,  1.04s/it]\u001b[A2025-06-23 11:45:41 | INFO | fairseq.tasks.translation | example hypothesis: der At besteht besteht aus mehr als 200 Arten verschiedenen Pflanzen und die Groß-.\n",
            "2025-06-23 11:45:41 | INFO | fairseq.tasks.translation | example reference: das Skelett besteht aus mehr als 200 Knochen verschiedener Formen und Größen.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  46% 13/28 [00:13<00:15,  1.03s/it]\u001b[A2025-06-23 11:45:42 | INFO | fairseq.tasks.translation | example hypothesis: wenn sie sie die verweitet, würde sich die sorbische Kultur mit dem FolkloreFolkloreFolkloreFolkloreFolkloreFolkloreFolkloreFolkloreFolkloreFolkloreFolkloreo ausgenommen.\n",
            "2025-06-23 11:45:42 | INFO | fairseq.tasks.translation | example reference: wenn sie untergehen würde, würde die sorbische Kultur zur reinen Folklore.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  50% 14/28 [00:14<00:14,  1.03s/it]\u001b[A2025-06-23 11:45:43 | INFO | fairseq.tasks.translation | example hypothesis: nach unserem Recht werde wir von uns in diesem Sinne dieser Änderungsanträge nach diesem Jahr nach dem neuen Abschließung nach.\n",
            "2025-06-23 11:45:43 | INFO | fairseq.tasks.translation | example reference: unseres Erachtens werden die von uns in diesem Sinne eingereichten Änderungsanträge nach der Unterzeichnung überflüssig sein.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  54% 15/28 [00:15<00:13,  1.04s/it]\u001b[A2025-06-23 11:45:44 | INFO | fairseq.tasks.translation | example hypothesis: dabei scheint darauf darauf darauf darauf, dass sich nur so viel Fragen, wie im Rat ist.\n",
            "2025-06-23 11:45:44 | INFO | fairseq.tasks.translation | example reference: dabei wurde darauf geachtet, dass nur so viele Kandidaten übergeben werden, wie Plätze im Rat sind.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  57% 16/28 [00:16<00:12,  1.00s/it]\u001b[A2025-06-23 11:45:45 | INFO | fairseq.tasks.translation | example hypothesis: Urban fuhr sich noch noch zu dem Sols, die Schlete, und ihm ihm.\n",
            "2025-06-23 11:45:45 | INFO | fairseq.tasks.translation | example reference: Urban fuhr noch zu Buschmann, dem Biologen, und zeigte ihm den Zettel.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  61% 17/28 [00:17<00:11,  1.00s/it]\u001b[A2025-06-23 11:45:46 | INFO | fairseq.tasks.translation | example hypothesis: die Schlete des Garten und der Rünt sind ein ziemlich ziemlich für die Vielfalt und die Lebens- für die Lebens- für die Lebens-.\n",
            "2025-06-23 11:45:46 | INFO | fairseq.tasks.translation | example reference: der Biergarten und der Rote Saal sind beliebte Orte für Familien- und Betriebsfeiern.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  64% 18/28 [00:18<00:09,  1.00it/s]\u001b[A2025-06-23 11:45:47 | INFO | fairseq.tasks.translation | example hypothesis: die Reation des Sorbischen Dresden zeigte sich in ihrem Rahmen ihrer Beschrift für die Verschließung der Verschließung der Verschließung der Verschließung für den.\n",
            "2025-06-23 11:45:47 | INFO | fairseq.tasks.translation | example reference: die Handwerkskammer Dresden setzt sich im Rahmen ihrer Interessenvertretung für die Verbesserung der genannten Rahmenbedingen ein.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  68% 19/28 [00:19<00:08,  1.00it/s]\u001b[A2025-06-23 11:45:48 | INFO | fairseq.tasks.translation | example hypothesis: die Inpolitik werden rund hundert Soldaten und auf dem Süns-Internet-weiteren weitere weitere weitere weitere Angebote.\n",
            "2025-06-23 11:45:48 | INFO | fairseq.tasks.translation | example reference: effektiv beteiligten sich rund einhundert Lausitzer und am flankierenden Online-Dialog weitere vierzig Akteure.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  71% 20/28 [00:20<00:08,  1.02s/it]\u001b[A2025-06-23 11:45:49 | INFO | fairseq.tasks.translation | example hypothesis: wie die Antwort in der Bautzener Sinin der Sarin, Cya, und Soa?\n",
            "2025-06-23 11:45:49 | INFO | fairseq.tasks.translation | example reference: wie erleben sie die Pandemie in Neuseeland, Mexiko, Australien und Tansania?\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  75% 21/28 [00:21<00:07,  1.07s/it]\u001b[A2025-06-23 11:45:50 | INFO | fairseq.tasks.translation | example hypothesis: da mir mir ihn seine As: \"\" \"\" \"\", \"weißt du, weißt\".\n",
            "2025-06-23 11:45:50 | INFO | fairseq.tasks.translation | example reference: na weil mir sein Gesang gefällt: \"rururu\" und \"lululu\", du weißt schon.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  79% 22/28 [00:23<00:06,  1.14s/it]\u001b[A2025-06-23 11:45:52 | INFO | fairseq.tasks.translation | example hypothesis: das Sorbische Lausitzer Lausitzer Lausitzer Parzinzinzzinzzzzzzzzzs mit dem anderen Bereich in den anderen Bereich und den anderen Landkreis in den anderen Raum.\n",
            "2025-06-23 11:45:52 | INFO | fairseq.tasks.translation | example reference: der Lausitzer Dampflok-Club aus Cottbus bietet Fahrten mit einem besonderen Zug nach Oberwiesenthal und Görlitz an.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  82% 23/28 [00:24<00:05,  1.15s/it]\u001b[A2025-06-23 11:45:53 | INFO | fairseq.tasks.translation | example hypothesis: \"wie das nur\" Buch \"Millionen Millionen Millionen Euro und ist in der Domowina-Domowina-Domowina auf der Domowina-Domowina-Domowina-Domowina-Domowina-Domowina.\n",
            "2025-06-23 11:45:53 | INFO | fairseq.tasks.translation | example reference: \"wie sage ich es nur?\" kostet 14,90 Euro und ist in der Smolerschen Verlagsbuchhandlung und im Internetshop des Domowina-Verlages erhältlich.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  86% 24/28 [00:25<00:04,  1.15s/it]\u001b[A2025-06-23 11:45:54 | INFO | fairseq.tasks.translation | example hypothesis: die Domowina wirkt ohne die Einträung und ohne die Ausschließung des Rahmen-Sinne-Sinne-Sinne \".\n",
            "2025-06-23 11:45:54 | INFO | fairseq.tasks.translation | example reference: die Domowina wirkt ohne Gewinn und verfolgt ausschließlich und unmittelbar gemeinnützige Zwecke im Sinne des Abschnitts \"Steuerbegünstigte Zwecke\" der Abgabenordnung.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  89% 25/28 [00:26<00:03,  1.14s/it]\u001b[A2025-06-23 11:45:55 | INFO | fairseq.tasks.translation | example hypothesis: die Abdenken auf die Landespolitik war, dass die Änderungsanträge im Rahmen der Sorben der Sorben der Sorben zum ersten Mal des sorbischen Volkes und zum ersten Mal mit dem ersten Mal des sorbischen Volkes \".\n",
            "2025-06-23 11:45:55 | INFO | fairseq.tasks.translation | example reference: die Erwartung an die sächsische Landespolitik war, dass die Vorschläge im Sinne der Entscheidung der Sorben eins zu eins übernommen werden und die ersten vier Kandidaten (mit den meisten \"sorbischen\" Stimmen auf der genannten Liste) vom Landtag bestätigt werden.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  93% 26/28 [00:28<00:02,  1.24s/it]\u001b[A2025-06-23 11:45:57 | INFO | fairseq.tasks.translation | example hypothesis: danach wurde das Lehrbuch das Lehrbuch \"\" \"M-\" der Domowina der Domowina der Domowina für das Thema der Domowina \", für die durch die Grundlage der Domowina im Rahmen der Domowina des Sächsischen 2 des Sächsischen 2 des Sächsischen 2\".\n",
            "2025-06-23 11:45:57 | INFO | fairseq.tasks.translation | example reference: nachdem die Lehrbuchreihe \"Pusteblume\" des Schrödel-Verlages auf Grundlage der überarbeiteten Lehrpläne für den Sachunterricht der Klassen 2 bis 4 als Lizenzausgabe \"Pusteblume\" im Domowina-Verlag aktualisiert wurde, liegt nun auch das Sachbuch für die 1 Klasse vor.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:  96% 27/28 [00:29<00:01,  1.27s/it]\u001b[A2025-06-23 11:45:58 | INFO | fairseq.tasks.translation | example hypothesis: die Beispiele dafür sind die Abstellung von und der Verleung, die Verleung von, wie auch in den, die Verlechen, die Verlechen, die Verlechen, die Verlechen, die Verlechen, die Verleliche oder in der Verlechen, die Verleliche oder in der Verleen-, die Verlechen, die Verlechen, die Verlechen, die Verlechen, die Verlechen, die Verleung\n",
            "2025-06-23 11:45:58 | INFO | fairseq.tasks.translation | example reference: Beispiele hierfür sind der Anbau von Zwischenfrüchten und Untersaaten, die Anlage von Grünstreifen, Pufferstreifen, Brache- und Blühflächen auf Ackerland, Anbau von bodenschonendem Ackerfutter / Leguminosen, Streifen- und Direktsaat sowie der ökologische Landbau.\n",
            "\n",
            "epoch 001 | valid on 'valid' subset: 100% 28/28 [00:30<00:00,  1.17s/it]\u001b[A\n",
            "                                                                        \u001b[A2025-06-23 11:45:58 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.619 | nll_loss 5.435 | ppl 43.27 | bleu 11.25 | wps 2622.6 | wpb 2810.7 | bsz 142.9 | num_updates 2444\n",
            "2025-06-23 11:45:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 2444 updates\n",
            "2025-06-23 11:45:58 | INFO | fairseq.trainer | Saving checkpoint to /content/bpc-project/checkpoints/sorbian_german_bpe/checkpoint1.pt\n",
            "2025-06-23 11:46:02 | INFO | fairseq.trainer | Finished saving checkpoint to /content/bpc-project/checkpoints/sorbian_german_bpe/checkpoint1.pt\n",
            "2025-06-23 11:46:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/sorbian_german_bpe/checkpoint1.pt (epoch 1 @ 2444 updates, score 11.25) (writing took 9.012695027000063 seconds)\n",
            "2025-06-23 11:46:07 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2025-06-23 11:46:07 | INFO | train | epoch 001 | loss 9.428 | nll_loss 8.782 | ppl 440.16 | wps 11353 | ups 2.93 | wpb 3877.4 | bsz 183.7 | num_updates 2444 | lr 0.0003055 | gnorm 1.557 | train_wall 783 | gb_free 12.4 | wall 836\n",
            "2025-06-23 11:46:07 | INFO | fairseq_cli.train | done training in 835.4 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Evaluate the model"
      ],
      "metadata": {
        "id": "4Vu0z9iji4Qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!uv run ./eval.sh sorbian_german_bpe bpe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZtvHemDi6BH",
        "outputId": "6fd7ead0-ad28-4f61-d230-16e6ec95bca6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-06-23 11:49:06] ===============================================\n",
            "[2025-06-23 11:49:06]        NMT Model Evaluation Report\n",
            "[2025-06-23 11:49:06] ===============================================\n",
            "[2025-06-23 11:49:06] Checkpoint: sorbian_german_bpe\n",
            "[2025-06-23 11:49:06] Dataset: bpe\n",
            "[2025-06-23 11:49:06] Split: test\n",
            "[2025-06-23 11:49:06] Timestamp: 20250623_114906\n",
            "[2025-06-23 11:49:06] Source file: dataset/output_moses/test.norm.hsb\n",
            "[2025-06-23 11:49:06] Reference file: dataset/output_moses/test.norm.de\n",
            "[2025-06-23 11:49:06] ===============================================\n",
            "[2025-06-23 11:49:06] Evaluating 2000 sentences...\n",
            "[2025-06-23 11:49:06] Step 1/3: Generating translations with fairseq...\n",
            "2025-06-23 11:49:12 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/sorbian_german_bpe/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 32, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 1.2, 'max_len_b': 10, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer='moses', bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=32, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=32, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='checkpoints/sorbian_german_bpe/checkpoint_best.pt', post_process='subword_nmt', quiet=False, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=1.2, max_len_b=10, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='transformer_iwslt_de_en', data='dataset/fairseq_bpe', source_lang='hsb', target_lang='de', load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, moses_no_dash_splits=False, moses_no_escape=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, pad=1, eos=2, unk=3, encoder_embed_dim=512, encoder_ffn_embed_dim=1024, encoder_attention_heads=4, encoder_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=1024, decoder_attention_heads=4, decoder_layers=6, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=False, decoder_embed_path=None, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=False, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_iwslt_de_en'), 'task': {'_name': 'translation', 'data': 'dataset/fairseq_bpe', 'source_lang': 'hsb', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': {'_name': 'moses', 'source_lang': 'hsb', 'target_lang': 'de', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2025-06-23 11:49:12 | INFO | fairseq.tasks.translation | [hsb] dictionary: 11024 types\n",
            "2025-06-23 11:49:12 | INFO | fairseq.tasks.translation | [de] dictionary: 10240 types\n",
            "2025-06-23 11:49:12 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/sorbian_german_bpe/checkpoint_best.pt\n",
            "2025-06-23 11:49:13 | INFO | fairseq.data.data_utils | loaded 2,000 examples from: dataset/fairseq_bpe/test.hsb-de.hsb\n",
            "2025-06-23 11:49:13 | INFO | fairseq.data.data_utils | loaded 2,000 examples from: dataset/fairseq_bpe/test.hsb-de.de\n",
            "2025-06-23 11:49:13 | INFO | fairseq.tasks.translation | dataset/fairseq_bpe test hsb-de 2000 examples\n",
            "2025-06-23 11:49:46 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2025-06-23 11:49:46 | INFO | fairseq_cli.generate | Translated 2,000 sentences (42,230 tokens) in 22.5s (88.81 sentences/s, 1875.12 tokens/s)\n",
            "[2025-06-23 11:49:47] Generated 2000 translations\n",
            "[2025-06-23 11:49:47] Step 2/3: Computing BLEU and chrF scores with sacrebleu...\n",
            "=== SacreBLEU Metrics ===\n",
            "Timestamp: 2025-06-23 11:49:48\n",
            "[\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 8.8,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.5.1\",\n",
            " \"verbose_score\": \"36.2/13.2/5.3/2.3 (BP = 1.000 ratio = 1.264 hyp_len = 35180 ref_len = 27835)\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"13a\",\n",
            " \"smooth\": \"exp\",\n",
            " \"version\": \"2.5.1\"\n",
            "},\n",
            "{\n",
            " \"name\": \"chrF2++\",\n",
            " \"score\": 34.7,\n",
            " \"signature\": \"nrefs:1|case:mixed|eff:yes|nc:6|nw:2|space:no|version:2.5.1\",\n",
            " \"nrefs\": \"1\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"yes\",\n",
            " \"nc\": \"6\",\n",
            " \"nw\": \"2\",\n",
            " \"space\": \"no\",\n",
            " \"version\": \"2.5.1\"\n",
            "}\n",
            "]\n",
            "\n",
            "[2025-06-23 11:49:48] Step 3/3: Computing COMET score...\n",
            "=== COMET Score ===\n",
            "Timestamp: 2025-06-23 11:51:17\n",
            "results/eval_sorbian_german_bpe_bpe_test_20250623_114906_hypotheses.txt\tscore: 0.3789\n",
            "\n",
            "[2025-06-23 11:51:17] ===============================================\n",
            "[2025-06-23 11:51:17] Evaluation completed successfully!\n",
            "[2025-06-23 11:51:17] ===============================================\n",
            "[2025-06-23 11:51:17] Results saved to:\n",
            "[2025-06-23 11:51:17]   Full log: results/eval_sorbian_german_bpe_bpe_test_20250623_114906_full.txt\n",
            "[2025-06-23 11:51:17]   Metrics: results/eval_sorbian_german_bpe_bpe_test_20250623_114906_metrics.txt\n",
            "[2025-06-23 11:51:17]   Hypotheses: results/eval_sorbian_german_bpe_bpe_test_20250623_114906_hypotheses.txt\n",
            "[2025-06-23 11:51:17]   Fairseq output: results/eval_sorbian_german_bpe_bpe_test_20250623_114906_fairseq_output.txt\n",
            "[2025-06-23 11:51:17] ===============================================\n",
            "\n",
            "=== QUICK SUMMARY ===\n",
            "Model: sorbian_german_bpe (bpe)\n",
            "Sentences: 2000\n",
            "BLEU = 8.8\n",
            "chrF2++ = 34.7\n",
            "COMET = 0.3789\n",
            "=======================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYLH5FMPnD8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}